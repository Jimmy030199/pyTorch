# verify_lookahead.py
import math
import torch
import torch.nn.functional as F

def scaled_dot_product_attention(q, k, v, mask=None):
    """
    q,k,v: (B,H,L,D), mask: (B,1,L,L) or (1,1,L,L) with True=allowed / False=blocked
    """
    d_k = q.size(-1)
    scores = q @ k.transpose(-2, -1) / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)  # 0=ç¦æ­¢ â†’ -inf
    attn = F.softmax(scores, dim=-1)
    out = attn @ v
    return out, attn

def build_look_ahead_mask(L: int):
    # ä¸‹ä¸‰è§’ç‚º 1ï¼ˆå…è¨±ï¼‰ï¼Œä¸Šä¸‰è§’ç‚º 0ï¼ˆç¦æ­¢ï¼‰
    return torch.tril(torch.ones((1, 1, L, L), dtype=torch.bool))

def build_look_ahead_mask(L):
    """å»ºç«‹ Look-ahead ä¸‹ä¸‰è§’çŸ©é™£"""
    mask = torch.tril(torch.ones((L, L), dtype=torch.int))
    return mask

if __name__ == "__main__":
    torch.manual_seed(7)
    B, H, L, D = 1, 1, 5, 4

    # ç”¢ç”Ÿå›ºå®šçš„ q/k/v æ–¹ä¾¿é‡ç¾
    q = torch.randn(B, H, L, D)
    k = torch.randn(B, H, L, D)
    v = torch.randn(B, H, L, D)

    # å»ºç«‹ Look-ahead mask ä¸¦å¥—ç”¨
    la_mask = build_look_ahead_mask(L)           # (1,1,L,L)
    out, attn = scaled_dot_product_attention(q, k, v, mask=la_mask)

    # ==== é©—è­‰ 1ï¼šä¸Šä¸‰è§’ï¼ˆæœªä¾†ä½ç½®ï¼‰ç‚º 0 ====
    # å–å‡ºæ³¨æ„åŠ›çŸ©é™£ (L,L)ï¼ŒæŠŠå°è§’ç·šä»¥ä¸Šçš„æœ€å¤§å€¼æŠ“å‡ºä¾†
    A = attn[0, 0]                                # (L,L)
    upper = torch.triu(A, diagonal=1)            # ä¸Šä¸‰è§’ï¼ˆä¸å«å°è§’ï¼‰
    print("â‘  ä¸Šä¸‰è§’æœ€å¤§å€¼ï¼ˆæ‡‰â‰ˆ0ï¼‰:", float(upper.max()))
    # ä¹Ÿå¯ç¡¬æ€§æª¢æŸ¥ï¼ˆå®¹å¿æµ®é»žèª¤å·®ï¼‰
    assert torch.allclose(upper, torch.zeros_like(upper), atol=1e-6), "æœªä¾†ä½ç½®æ²’æœ‰å®Œå…¨è¢«é®ï¼"

    # ==== é©—è­‰ 2ï¼šç¬¬ 1 å€‹ token åªèƒ½çœ‹è‡ªå·± ====
    row0 = A[0]                                   # (L,)
    print("â‘¡ attn_weights[0,0,0] å‘é‡ï¼š", row0.tolist())
    print("   éžé›¶ç´¢å¼•ï¼š", [i for i,v in enumerate(row0) if v > 1e-9])
    # åªå‰© index=0 æ‡‰ç‚ºéžé›¶
    assert (row0[0] > 1e-9) and torch.all(row0[1:] < 1e-9), "ç¬¬1å€‹ token å»èƒ½çœ‹åˆ°æœªä¾†ï¼"

    # ==== é©—è­‰ 3ï¼šç¬¬ 3 å€‹ token åªèƒ½çœ‹å‰ 3 å€‹ ====
    row2 = A[2]                                   # (L,)
    print("â‘¢ attn_weights[0,0,2] å‘é‡ï¼š", row2.tolist())
    print("   éžé›¶ç´¢å¼•ï¼š", [i for i,v in enumerate(row2) if v > 1e-9])
    # åªå…è¨± 0,1,2 ä½ç½®éžé›¶
    assert torch.all(row2[:3] > 1e-9) and torch.all(row2[3:] < 1e-9), "ç¬¬3å€‹ token çœ‹åˆ°äº†æœªä¾†ï¼"

    # å…¶ä»– sanity checkï¼šæ¯åˆ—ç¸½å’Œâ‰ˆ1
    rowsum = A.sum(-1)
    print("â‘£ æ¯åˆ—ç¸½å’Œï¼ˆæ‡‰â‰ˆ1ï¼‰ï¼š", rowsum.tolist())
    assert torch.allclose(rowsum, torch.ones_like(rowsum), atol=1e-6)

    print("\nâœ… é©—è­‰é€šéŽï¼šLook-ahead Mask æ­£å¸¸é˜»æ“‹æœªä¾†ä½ç½®ã€‚")


   


    
    L = 5  # åºåˆ—é•·åº¦ï¼Œå¯è‡ªè¡Œæ”¹
    mask = build_look_ahead_mask(L)
    print("ðŸ”» Look-ahead Mask ä¸‹ä¸‰è§’çŸ©é™£ (1=å…è¨±çœ‹, 0=é®ä½):\n")
    print(mask)

    

